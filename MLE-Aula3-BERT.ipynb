{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c310fd9a-0ec2-4ca2-a0fd-1d00af2f8de0",
   "metadata": {},
   "source": [
    "# BERT\n",
    "\n",
    "BERT, Bidirectional Encoder Representatios from Transformers, √© um outro tipo de modelo de representa√ß√£o de linguagem. Foi introduzido em 2018 pelo Google e seu artigo pode ser consultado aqui: [link](https://arxiv.org/pdf/1810.04805)\n",
    "\n",
    "Tr√™s raz√µes principais tornam o BERT um dos grandes avan√ßos em NLP:\n",
    "\n",
    "1. demonstra um sofisticado conhecimento de linguagem, atingindo performance humana em algumas tarefas\n",
    "2. pode ser aplicado numa variedade de tarefas\n",
    "3. oferece o benef√≠cio de pr√©-treino + fine-tuning: o BERT foi treinado pelo Google num corpus de texto muito grande e voc√™ pode se apoderar desse conhecimento de linguagem tomando o modelo pr√©-treinado e aplicar o fine-tuning em sua pr√≥pria aplica√ß√£o. \n",
    "\n",
    "Entretanto, n√£o estamos ainda no n√≠vel de por o BERT em qualquer problema e esperar grandes resultados. Assim, o objetivo dessa aula ser√° o de fornecer o entendimento de como BERT funciona e o que ele pode ou n√£o pode fazer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3b82f-aea7-4900-97fe-85824c7d3a69",
   "metadata": {},
   "source": [
    "## Pre-training e Fine-tuning\n",
    "\n",
    "Antes de adentrarmos em como o BERT funciona √© importante que tenhamos conceitos claros do que √© **pre-training** e **fine-tuning**, o que, combinados, formam a t√©cnica que chamamos de *transfer learning*. \n",
    "\n",
    "Quando estudamos o BERT, vemos que as duas principais contribui√ß√µes s√£o essas duas:\n",
    "\n",
    "1. *Masked Language Model (MLM)*\n",
    "2. *Next Sentence Prediction (NSP)*\n",
    "\n",
    "Considere o seguinte exemplo sobre essas duas atividades:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57ca1d-d9e7-45f0-9421-74f104e03a94",
   "metadata": {},
   "source": [
    "<img src=\"img/MLM_NSP.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3477215-aaea-4fed-a0c6-fbf341280a96",
   "metadata": {},
   "source": [
    "Isto √© que o BERT deve fazer: \n",
    "\n",
    "1. MLM - predizer a palavra tracejada (simple)\n",
    "2. NSP - a senten√ßa B (laranja) foi encontrada imediatamente depois da sentenca A (azul) ou em outro lugar? O BERT deveria retornar que elas s√£o consecutivas.\n",
    "\n",
    "Extrapolando, o BERT foi treinado para executar essas duas tarefas puramente como uma forma de for√ßar um sofisticado entendimento da linguagem. \n",
    "\n",
    "Mas o BERT n√£o seria t√£o interessante se tudo o que ele pode fazer fosse predizer palavras faltantes (MLM) e dizer se duas senten√ßas s√£o consecutivas ou n√£o. A principal parte do BERT √© uma rede neural de 12 camadas extensa que processa texto. O MLM e o NSP adicionam, cada um, uma √∫nica camada de classifica√ß√£o ao output do BERT para executar suas respectivas atividades. \n",
    "\n",
    "Observe a ilustra√ß√£o abaixo que mostra que o mesmo modelo BERT pr√©-treinado pode ser usada para executar An√°lise de Sentimento ou Extra√ß√£o de Entidade Nomeada (NER) com a √∫nica diferen√ßa sendo a camada final do modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1cceb-6c03-4b58-a0dc-ab9dcfbd6855",
   "metadata": {},
   "source": [
    "<img src=\"img/bert_tasks.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca3d754-f436-47c3-87be-88b25c732fc3",
   "metadata": {},
   "source": [
    "Assim, por exemplo, se voc√™ deseja aplicar o BERT para uma tarefa espec√≠fica de classifica√ß√£o de texto, voc√™ deveria pegar o modelo BERT pr√©-treinado, adicionar uma camada de neur√¥nios n√£o treinados no final e treinar o novo modelo combinado no seu dataset. Este passo final √© denominado *fine-tuning*, visto que a quantidade de treino requirido para adaptar o BERT para sua tarefa √© muito pequena quando comparada ao tempo que a Google gastou para treinar o BERT. Mesmo assim, a tarefa fine-tuning √© custosa computacionalmente falando. \n",
    "\n",
    "Dessa maneira, esta t√©cnica de adicionar uma pequena tarefa espec√≠fica ao final de um grande modelo pr√©-treinado e aplicar fine-tuning ao resultado √© conhecido como **Transfer Learning**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31423a-aaaa-4925-9abb-2a077591c1dc",
   "metadata": {},
   "source": [
    "Mas afinal, por qual motivo usar Transfer Learning ao inv√©s de treinar diretamente um modelo de deep learning? Exsitem tr√™s principais raz√µes:\n",
    "\n",
    "1. **Desenvolvimento r√°pido:** como j√° h√° uma quantidade massiva de dados treinados, os autores recomendam de 2 a 4 √©pocas de treinamento para fine-tuning do BERT para uma tarefa espec√≠fica. \n",
    "\n",
    "2. **Menos dados:** visto que a grande maioria de dados j√° foi usada para treinar o BERT\n",
    "\n",
    "3. **Melhores resultados:** este procedimento de fine-tuning demonstrou atingir resultados do estado-da-arte em tarefas como classifica√ß√£o, QA, similaridade sem√¢ntica, entre outros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aff093-c0d7-4c53-b85b-8332d0e7678d",
   "metadata": {},
   "source": [
    "### Formato de Input e Output do BERT\n",
    "\n",
    "Antes de entrar nos detalhes da arquitetura interna do BERT, √© importante ter uma clara ideia de como o BERT faz a ingest√£o de texto e o que exatamente ele retorna. \n",
    "\n",
    "O primeiro passo √© o **tokenizer**, que toma um texto limpo e o divide em tokens que o BERT faz ingest√£o. O motivo do BERT prover seu pr√≥prio tokenizer √© que ele possui um vocabul√°rio fixo de tokens, com um embedding associado a cada um. Mas ai surge uma quest√£o: como ele lida com palavras que n√£o est√£o no vocabul√°rio? Ai entra em cena o segundo passo: **lidando com palavras fora do vocabul√°rio**. \n",
    "\n",
    "Se uma palavra n√£o est√° presente no vobabul√°rio do BERT ele quebra ela em sub-palavras. E, se mesmo assim as sub-palavras n√£o estiverem no vocabul√°rio, o BERT pode as quebrar em caracteres individuais. Cada sub-palavra ou caracter individual se torna um token separado, representado por seu pr√≥prio embedding. Al√©m disso, o BERT possui tokens para representar caracteres de pontua√ß√£o e a √∫nica coisa que ele descarta no processo de tekeniza√ß√£o √© o espa√ßo em branco. \n",
    "\n",
    "Assim, quando aplicamos o BERT a um peda√ßo de texto, o tokenizer ir√° dividir o texto em tokens, procurar os embeddings desses tokens e estes ser√£o os reais inputs do BERT, sendo cada um deles composto por 768 features. De maneira bem simples, o que o BERT faz √© tomar esses embeddings como input e solta como output uma vers√£o melhorada desses embeddings. \n",
    "\n",
    "E para entender como o BERT cria essa vers√£o melhorada de uma √∫nica palavra (embedding), considere o exemplo abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd044a-4e58-4238-a419-e64ae27b1b40",
   "metadata": {},
   "source": [
    "<img src=\"img/input_melhorado.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f474c20-ccaf-451d-964b-84f4aaa15504",
   "metadata": {},
   "source": [
    "Entretanto, na pr√°tica, o BERT processa cada palavra independentemente e, por isso, √© poss√≠vel paralelizar o processo e executar todas as palavras de input atrav√©s do BERT \"de uma s√≥ vez\". Veja a imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbb315-f6dc-4ccc-b87b-9d456b31918b",
   "metadata": {},
   "source": [
    "<img src=\"img/bert_paralel.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca765db-74cc-4ae0-9ba8-9a7ee3d4c500",
   "metadata": {},
   "source": [
    "Essa rede de conex√µes ilustra que, para cada palavra de input, vamos incorporar todos os embeddings das outras palavras tamb√©m.\n",
    "\n",
    "Esse processo de pegar um conjunto de embeddings e melhor√°-lo √©, na verdade, repetido 12 vezes no BERT, como pode ser visto na imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db17f27-5a1e-4bd6-9e58-3f2588576cab",
   "metadata": {},
   "source": [
    "<img src=\"img/12_layers.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333bd15d-0099-4b54-b9d3-1613ff7f199c",
   "metadata": {},
   "source": [
    "Esse processo ilustra alguns aspectos importantes do BERT:\n",
    "\n",
    "* a \"rede de conex√£o\" mostra que todas as palavras s√£o incorporadas em processar cada palavra\n",
    "* a mesma arquitetura √© aplicada a cada palavra em paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d8f175-0492-4157-96f1-50dfc03a3dc4",
   "metadata": {},
   "source": [
    "Um ponto importante a ser dito √© que o arranjo de palavras do exemplo acima, em que elas aparcem na ordem de uma correta senten√ßa, n√£o √© uma necessidade do BERT. Na realidade, o BERT n√£o posssui nenhum conhecimento expl√≠cito da ordem da palavra. Entretanto, ele requer alguma no√ß√£o de ordem da palavra e a maneira como ele faz isso √© bastante particular. O BERT possui um conjunto de 512 embeddings conhecidos como **positional encoding (PE)**, que simplesmente somamos ao embedding da palavra correspondente, conforme ilustra√ß√£o a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e924f-f62e-4066-868a-d6547035a40c",
   "metadata": {},
   "source": [
    "<img src=\"img/PE.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b88ad-b7d7-4842-93f8-fc8f43ce6975",
   "metadata": {},
   "source": [
    "Importante notar que o PE √© adicionado apenas antes da primeira camada e n√£o entre quaisquer outras camadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77520c55-ce75-4c04-bbfc-97bd2a275d44",
   "metadata": {},
   "source": [
    "## Arquitetura do BERT\n",
    "\n",
    "At√© aqui, sabemos como o BERT tokeniza o texto e sabemos que ele produz um conjunto melhorado de embeddings para cada token, mas qual o mecanismo por tr√°s desse processo de melhora? Como o BERT realmente d√° sentido a linguagem?\n",
    "\n",
    "A arquitetura do BERT vem diretamente da arquitetura do Transformer - que est√° mais bem explicada no material de apoio e ser√° objetivo de estudo na disciplina de IA Generativa. A parte mais importante dessa arquitetura √© uma t√©cnica denominada **Self-attention**.\n",
    "\n",
    "Anteriormente, analisamos o exemplo abaixo em que comentamos que, ao melhorar o embedding da palavra \"like\", tamb√©m incorporamos os embeddings de outras palavras na senten√ßa. \n",
    "\n",
    "Self-attention √© o peda√ßo que realiza essa incorpora√ß√£o de outros embeddings.\n",
    "\n",
    "Quando produz um embedding melhorado para uma palavra, self-attention ir√° pegar a m√©dia ponderada dos embeddings de outras palavras de contexto. O peso do self-attention atribui para cada palavra de contexto o quanto de aten√ß√£o que ser√° dada a essa palavra de contexto. Considere o seguinte exemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61835b9-f07f-4eb5-8d6d-b3cef3938b8b",
   "metadata": {},
   "source": [
    "<img src=\"img/self_attention.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b6a4f-8427-4b72-a739-70dd3daf8856",
   "metadata": {},
   "source": [
    "Ao processar a palavra \"he\", self-attention fornece pesos para as diferentes palavras na senten√ßa (quanto mais escuro o tom, maior o peso). Neste caso, BERT est√° focando primeiramente no nome do personagem a quem \"he\" se refere - \"Bert\". \n",
    "\n",
    "Algumas notas importantes: \n",
    "\n",
    "1. Ser√° atribu√≠do um peso a cada palavra\n",
    "2. O embedding para a palavra de input √© inclu√≠do na m√©dia ponderada\n",
    "3. Os pesos s√£o calculados com a fun√ß√£o SoftMax\n",
    "\n",
    "Assim, o resultado de uma palavra melhorada √© dado pela seguinte fun√ß√£o:\n",
    "\n",
    "$\\bar{x} = \\sum_{i=1}^{n} w_i x_i$\n",
    "\n",
    "em que:\n",
    "\n",
    "* $n$ √© o n√∫mero de palavras na senten√ßa\n",
    "* $i$ √© a posi√ß√£o da palavra na senten√ßa\n",
    "* $x_i$ √© o embedding da palavra na posi√ß√£o $i$\n",
    "* $w_i$ √© o valor do peso dado a palavra na posi√ß√£o $i$\n",
    "* $\\bar{x}$ √© o embedding melhorado da palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd8972-a682-4c18-9d64-6c3c2030d6ab",
   "metadata": {},
   "source": [
    "Ent√£o, como calculamos os pesos que ser√£o atribu√≠dos a cada palavra numa senten√ßa? Essencialmente, iremos calcular o produto escalar da palavra de input pela palavra de contexto, que √© a que queremos determinar o peso. Isso ser√° feito para todas as palavras de contexto, passa por uma fun√ß√£o SoftMax e obteremos nossos pesos, conforme detalhado na imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99cf222-a455-461f-bea0-a34447666060",
   "metadata": {},
   "source": [
    "<img src=\"img/calculo_pesos.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7128e02-fdcc-407c-9113-24952008e503",
   "metadata": {},
   "source": [
    "Dentro de uma √∫nica camada do BERT, existe mais um componente relevante depois do self-attention: uma rede neural de 3 camadas, referenciada como Feed Forward Neural Network no paper original. A imagem abaixo ilustra essa rede:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1d6f9-f1ab-4ab2-add6-21e9c200a8b3",
   "metadata": {},
   "source": [
    "<img src=\"img/ffn.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce6bff-df54-44de-943f-ca57734175b2",
   "metadata": {},
   "source": [
    "A conven√ß√£o adotada no paper tanto do Transformer quanto do BERT foi de configurar o n√∫mero de neur√¥nios na camada oculta como sendo 4x o tamanho do embedding. Assim $4x768 = 3072$ neur√¥nios ocultos. Al√©m disso, a fun√ß√£o de ativa√ß√£o GeLu (mais detalhes [aqui](https://medium.com/@shauryagoel/gelu-gaussian-error-linear-unit-4ec59fb2e47c)) e essa FFN √© respons√°vel pela maior parte dos pesos do BERT. \n",
    "\n",
    "Mas anteriormente dissemos que o BERT possui 12 camadas e cada uma delas √© respons√°vel por prestar aten√ß√£o numa determinada por√ß√£o do texto, ou, tecnicamente dizendo, cada uma respons√°vel por executar uma fun√ß√£o. Esse mecanismo √© conhecido como **Multi-headed attention**. Dessa, uma √∫nica palavra de input ser√° executada, junto com suas palavras de contexto, atrav√©s de 12 √∫nicas inst√¢ncias de self-attention, o que, consequentemente, gera 12 √∫nicos embeddings melhorados. Assim, fica a quest√£o: como combinar esses 12 resultados em apenas um? \n",
    "\n",
    "Para resolver esse problema, adicionamos uma nova camada para melhor combinar esses 12 resultados num embedding de dimens√£o 768."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63212d",
   "metadata": {},
   "source": [
    "**1. A Conven√ß√£o de Tamanho da Camada Oculta e a FFN:**\n",
    "\n",
    "*   **Conven√ß√£o:** Em arquiteturas como o Transformer original e o BERT, adotou-se um padr√£o espec√≠fico para o tamanho da camada oculta da **Rede Neural Feed-Forward (FFN)** que √© aplicada ap√≥s a aten√ß√£o.\n",
    "*   **Rela√ß√£o:** O n√∫mero de neur√¥nios nessa camada oculta √© **4 vezes** o tamanho do embedding (a dimens√£o vetorial das palavras ou tokens). No caso do BERT-base, o tamanho do embedding √© 768.\n",
    "*   **C√°lculo:** Portanto, a camada oculta da FFN tem `4 x 768 = 3.072` neur√¥nios.\n",
    "*   **Fun√ß√£o de Ativa√ß√£o:** Essa FFN usa a fun√ß√£o de ativa√ß√£o **GELU (Gaussian Error Linear Unit)**. A GELU, como explicado no artigo referenciado, √© uma fun√ß√£o de ativa√ß√£o que tenta combinar aspectos de fun√ß√µes lineares e estoc√°sticos, oferecendo propriedades interessantes para o treinamento de redes profundas.\n",
    "*   **Peso Computacional:** A FFN, com sua expans√£o para 3.072 neur√¥nios e subsequente compress√£o de volta para 768, √© respons√°vel pela **maioria dos par√¢metros (pesos)** do modelo BERT. Cada uma das FFNs em cada camada contribui significativamente para o tamanho total do modelo.\n",
    "\n",
    "**2. Revisitando a Multi-Headed Self-Attention:**\n",
    "\n",
    "*   **Quantidade de Camadas:** O BERT (base) consiste de **12 camadas** (ou blocos) empilhadas.\n",
    "*   **Fun√ß√£o de Cada Camada:** Cada uma dessas 12 camadas cont√©m um mecanismo de **Multi-Head Self-Attention**. (A frase no seu texto original parece confundir a camada inteira com apenas o mecanismo de aten√ß√£o, embora a ideia esteja pr√≥xima).\n",
    "*   **Multi-Headed Attention:** O termo \"Multi-Headed\" significa que, dentro de *cada* camada, o mecanismo de aten√ß√£o √© calculado em **m√∫ltiplos \"cabe√ßalhos\" (heads)** em paralelo. No BERT-base, s√£o usados 12 cabe√ßalhos por camada. Cada cabe√ßalho aprende a focar em diferentes tipos de relacionamentos entre as palavras.\n",
    "*   **Processamento:** Cada token (palavra ou parte de palavra) de entrada √© processado, juntamente com o contexto (os outros tokens na sequ√™ncia), por *todos* os cabe√ßalhos *dentro* daquela camada de aten√ß√£o. Isso permite capturar diferentes tipos de depend√™ncias contextuais.\n",
    "*   **Resultado da Attention:** Cada um dos 12 cabe√ßalhos produz um embedding contextualizado intermedi√°rio. Esses embeddings dos diferentes cabe√ßalhos s√£o concatenados e ent√£o linearmente projetados de volta para a dimens√£o original (768 no BERT-base). Portanto, *cada camada* produz **um** embedding contextualizado final para cada token de entrada, mas esse resultado √© fruto da combina√ß√£o dos 12 cabe√ßalhos *dentro* dessa camada.\n",
    "\n",
    "**3. Combinando os Resultados (Resposta √† \"Quest√£o\"):**\n",
    "\n",
    "*   **\"12 √önicas Inst√¢ncias\":** Esta parte da sua frase pode gerar confus√£o. N√£o √© que uma palavra √© processada por 12 *inst√¢ncias separadas* de self-attention *totalmente independentes* que geram 12 embeddings finais distintos *por camada*. Em vez disso, dentro de *cada uma* das 12 *camadas*, a palavra passa por um mecanismo de *Multi-Head* Self-Attention (que, no BERT-base, tem 12 cabe√ßalhos *dentro* da camada).\n",
    "*   **\"12 √önicos Embeddings Melhorados\":** Se interpretarmos isso como os embeddings resultantes *ap√≥s cada uma das 12 camadas* (ou seja, o embedding final de sa√≠da de cada camada, j√° processado pela attention e pela FFN dessa camada), ent√£o sim, ao longo das 12 camadas, o token passa por 12 transforma√ß√µes, resultando em 12 representa√ß√µes intermedi√°rias (com a √∫ltima sendo a sa√≠da final do modelo).\n",
    "*   **\"Como combinar esses 12 resultados em apenas um?\":** A **pergunta em si parte de uma premissa ligeiramente incorreta**. O modelo **n√£o** combina 12 embeddings distintos produzidos *simultaneamente* por uma √∫nica camada. Em vez disso, o que acontece √© um **processo sequencial**:\n",
    "    1.  O embedding de entrada √© processado pela *camada 1* (attention + FFN), produzindo um novo embedding (dimens√£o 768).\n",
    "    2.  Esse novo embedding √© a entrada para a *camada 2*, que o processa novamente (attention + FFN).\n",
    "    3.  Esse processo se repete at√© a *camada 12*.\n",
    "    4.  A sa√≠da da *camada 12* √© o embedding contextualizado final do BERT para aquele token.\n",
    "*   **\"Para resolver esse problema, adicionamos uma nova camada...\":** Esta parte tamb√©m est√° confusa. **N√£o** √© adicionada uma camada *extra* *ap√≥s* as 12 camadas para combinar os resultados das 12 camadas. O *mecanismo de combina√ß√£o* que voc√™ est√° descrevendo (transformar 12 representa√ß√µes em 1) **j√° est√° incorporado dentro de *cada*** mecanismo de Multi-Head Attention.\n",
    "    *   Dentro de *cada* camada: Os resultados dos 12 *cabe√ßalhos* (heads) de attention s√£o concatenados (resultando em 12 * 64 = 768 dimens√µes, assumindo 768/12 = 64 por head) e ent√£o passam por uma camada linear (`LayerNorm + Linear`) que os projeta de volta para 768 dimens√µes. Esta √© a etapa que combina os resultados dos m√∫ltiplos cabe√ßalhos *dentro* daquela camada.\n",
    "    *   O processo de *passar* o resultado de uma camada para a pr√≥xima √© o que \"combina\" as transforma√ß√µes das 12 *camadas*, mas √© um processo sequencial, n√£o uma combina√ß√£o paralela de 12 sa√≠das finais.\n",
    "\n",
    "**Em resumo:**\n",
    "\n",
    "*   A FFN usa 4x o tamanho do embedding e GELU, sendo respons√°vel pela maior parte dos par√¢metros.\n",
    "*   Cada uma das 12 *camadas* do BERT cont√©m um mecanismo de Multi-Head Attention (com 12 *cabe√ßalhos* dentro).\n",
    "*   Os 12 *cabe√ßalhos* dentro de *cada* camada s√£o combinados (concatenados e projetados) *dentro* dessa camada.\n",
    "*   O resultado final √© obtido ap√≥s passar sequencialmente pelas 12 *camadas*, n√£o combinando 12 sa√≠das finais separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2f3e6",
   "metadata": {},
   "source": [
    "<img src=\"img/bert_encoder_block_diagram.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d8b695",
   "metadata": {},
   "source": [
    "\n",
    "## 1) FFN ‚Äú4√óhidden‚Äù + GeLU\n",
    "\n",
    "* No BERT-base: **hidden size H = 768**. A MLP (FFN) de cada bloco usa **intermediate = 4H = 3072** e faz **768 ‚Üí 3072 ‚Üí 768**, com **GeLU** no meio.\n",
    "* A GeLU √© basicamente (x \\cdot \\Phi(x)) (ou a aproxima√ß√£o com `tanh` do paper do BERT): ela ‚Äúabre‚Äù mais para valores positivos e atenua negativos, o que costuma funcionar melhor que ReLU nessa arquitetura.\n",
    "* Por que ‚Äú4√ó‚Äù? Foi a conven√ß√£o introduzida no Transformer e seguida no BERT: d√° **capacidade n√£o-linear** suficiente sem explodir custo. Variantes usam 2√ó, 4√ó, 8√ó conforme o budget.\n",
    "\n",
    "üí° **Par√¢metros (por bloco, BERT-base):**\n",
    "\n",
    "* Aten√ß√£o (Q,K,V,O): ~**2,36 M**\n",
    "* FFN (768√ó3072 + 3072√ó768): ~**4,72 M**\n",
    "* Ou seja, **a FFN domina os pesos dentro de cada bloco** (e no modelo inteiro ela disputa com a tabela de embeddings). No total, BERT-base ‚âà **110M** par√¢metros.\n",
    "\n",
    "## 2) ‚Äú12 camadas‚Äù ‚â† ‚Äú12 aten√ß√µes‚Äù\n",
    "\n",
    "No BERT-base h√° **12 camadas (blocos)** empilhadas **em s√©rie**.\n",
    "**Dentro de cada camada** existe **Multi-Head Attention com 12 cabe√ßas**. S√£o ‚Äúdois doze‚Äù diferentes:\n",
    "\n",
    "* **Camadas (12)**: empilhadas; a sa√≠da da camada 1 entra na 2, e assim por diante.\n",
    "* **Cabe√ßas (12 por camada)**: rodam **em paralelo** dentro daquela camada.\n",
    "\n",
    "## 3) O que acontece com 1 token dentro de UMA camada\n",
    "\n",
    "Suponha entrada com forma ([B, T, 768]) (batch, tamanho da sequ√™ncia, hidden):\n",
    "\n",
    "1. Projeta **Q, K, V**: tr√™s matrizes lineares (768 \\to 768).\n",
    "2. Divide em **12 cabe√ßas**, ent√£o cada cabe√ßa fica com **dimens√£o 64** (pois (768/12=64)).\n",
    "3. Cada cabe√ßa faz **self-attention** (scaled dot-product) e produz um vetor ([B, T, 64]).\n",
    "4. **Concatena** as 12 sa√≠das: ([B, T, 12\\cdot64] = [B, T, 768]).\n",
    "5. Aplica uma **proje√ß√£o linear (W_O: 768\\to768)** para misturar as cabe√ßas.\n",
    "6. **Residual + LayerNorm**.\n",
    "7. Passa na **FFN 768‚Üí3072‚Üí768 com GeLU**.\n",
    "8. **Residual + LayerNorm** e segue para a pr√≥xima camada.\n",
    "\n",
    "üëâ Portanto, **n√£o existem ‚Äú12 embeddings finais‚Äù a serem combinados** fora do mecanismo: as **12 cabe√ßas** j√° s√£o combinadas **dentro** da pr√≥pria aten√ß√£o via **concatena√ß√£o + proje√ß√£o (W_O)**, resultando novamente em um √∫nico embedding de **768** por token **naquela camada**.\n",
    "\n",
    "## 4) E como sai ‚Äúum‚Äù vetor no fim?\n",
    "\n",
    "Depende da tarefa:\n",
    "\n",
    "* **Por token** (tagging, QA span): usa-se o vetor de **cada token** da **√∫ltima camada** (dim 768).\n",
    "* **Por senten√ßa** (classifica√ß√£o): usa-se o **[CLS]** da √∫ltima camada. O BERT ainda aplica um **‚Äúpooler‚Äù** (dense 768‚Üí768 com `tanh`) sobre o [CLS].\n",
    "* Algumas pr√°ticas somam ou concatenam as **√∫ltimas 4 camadas** por token, mas isso √© op√ß√£o de fine-tuning, n√£o do pr√©-treino base.\n",
    "\n",
    "## 5) Se quiser resumir em uma linha\n",
    "\n",
    "* **12 camadas** em s√©rie.\n",
    "* **Cada camada** faz: **MHA (12 cabe√ßas)** ‚Üí concatena ‚Üí **proje√ß√£o (W_O)** ‚Üí residual/LN ‚Üí **FFN 4√óH (GeLU)** ‚Üí residual/LN.\n",
    "* A **combina√ß√£o das 12 cabe√ßas** √© parte **intr√≠nseca** da MHA (concat + (W_O)), n√£o uma ‚Äúcamada extra‚Äù separada depois.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85f3a7-8efb-47c8-8e8d-79a413192c2d",
   "metadata": {},
   "source": [
    "# Pr√°tica\n",
    "\n",
    "Vamos agora entender como aplicar o BERT a um problema de classifica√ß√£o de texto.\n",
    "\n",
    "Para construir um modelo de classifica√ß√£o de texto usando BERT, podemos aplicar duas estrat√©gias (ligeiramente) diferentes. Como mencionado acima, o BERT √© usado para codificar textos em um vetor. O modelo de classifica√ß√£o que constru√≠mos no BERT consiste em classificar esses vetores usando algoritmos de ML. Ent√£o, podemos:\n",
    "\n",
    "1. Aplicar BERT aos textos como etapas de pr√©-processamento e, em seguida, construir um modelo de ML que classifica esses vetores\n",
    "2. Construir um modelo que come√ßa com BERT (onde congelamos os par√¢metros ao treinar o modelo) e, em seguida, construir sobre o BERT uma camada que classifica esses vetores\n",
    "\n",
    "A vantagem do primeiro m√©todo √© que precisamos passar o texto (dados de treinamento e teste) apenas uma vez pelo BERT, e n√£o para cada √©poca no treinamento, reduzindo significativamente o tempo de treinamento. A vantagem do segundo m√©todo √© que n√£o precisamos construir uma etapa adicional para o pipeline, uma vez que o de ponta a ponta (do texto √† classifica√ß√£o) √© fornecido pelo tokenizador e o pr√≥prio modelo.\n",
    "\n",
    "Para fins pedag√≥gicos, usaremos a segunda abordagem. Em um caso real, a escolha da abordagem dependeria do uso do modelo. Se precisarmos treinar o modelo regularmente, eu preferiria a primeira abordagem. Se o modelo tiver que ser treinado apenas uma vez, eu escolheria a segunda abordagem.\n",
    "\n",
    "Usaremos o modelo DistilBERT da biblioteca Python transformers, que √© fornecida pela empresa Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96097ace-d3e1-4bdb-bb90-fd0e000dfaf1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Vamos usar um pequeno dataset nessa pr√°tica: o BBC News, que consistem em aproximadamente 2000 amostras e pode ser obtido [aqui](https://www.kaggle.com/datasets/sainijagjit/bbc-dataset?resource=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27641524-a1fa-4428-8555-e750c0d2f4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "# Download the dataset and put it in subfolder called data\n",
    "df = pd.read_csv(\"Bases/bbc-text.csv\")\n",
    "df = df[[\"category\", \"text\"]]\n",
    "\n",
    "# Show the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4487c8-2ebf-44f6-95b4-7102306fe23f",
   "metadata": {},
   "source": [
    "Primeiro, vamos analisar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e302e09-51fd-4057-91f8-52bafeef5b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news: 2225\n",
      "----------------------------------------\n",
      "Split by category:\n",
      "category\n",
      "sport            511\n",
      "business         510\n",
      "politics         417\n",
      "tech             401\n",
      "entertainment    386\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Number of categories: 5\n"
     ]
    }
   ],
   "source": [
    "print('Total number of news: {}'.format(len(df)))\n",
    "print(40*'-')\n",
    "print('Split by category:')\n",
    "print(df[\"category\"].value_counts())\n",
    "print(40*'-')\n",
    "nr_categories = len(df[\"category\"].unique())\n",
    "print(\"Number of categories: {n}\".format(n=nr_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b753f7c-e152-41dd-987f-4c840a1141a3",
   "metadata": {},
   "source": [
    "Obtemos um n√∫mero total de entradas de 2.225, que s√£o relativamente uniformemente divididas em cinco classes. Isso nos permite aplicar m√©todos padr√£o, pois n√£o h√° necessidade de super ou subponderar algumas classes.\n",
    "\n",
    "Finalmente, vamos dar uma olhada em um exemplo espec√≠fico para ter uma impress√£o concreta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df660dcf-eb30-4c0c-8e2b-0856b61b49a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:  entertainment\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Text:\n",
      "housewives lift channel 4 ratings the debut of us television hit desperate housewives has helped lift channel 4 s january audience share by 12% compared to last year.  other successes such as celebrity big brother and the simpsons have enabled the broadcaster to surpass bbc two for the first month since last july. bbc two s share of the audience fell from 11.2% to 9.6% last month in comparison with january 2004. celebrity big brother attracted fewer viewers than its 2002 series.  comedy drama desperate housewives managed to pull in five million viewers at one point during its run to date  attracting a quarter of the television audience. the two main television channels  bbc1 and itv1  have both seen their monthly audience share decline in a year on year comparison for january  while five s proportion remained the same at a slender 6.3%. digital multi-channel tv is continuing to be the strongest area of growth  with the bbc reporting freeview box ownership of five million  including one million sales in the last portion of 2004. its share of the audience soared by 20% in january 2005 compared with last year  and currently stands at an average of 28.6%.\n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "print('Category: ',df['category'][n])\n",
    "print(100*'-')\n",
    "print('Text:')\n",
    "print(df['text'][n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd850c43-1bb8-4f9f-8f94-6813078ca612",
   "metadata": {},
   "source": [
    "As labels precisam ser convertidas para n√∫meros. Vamos fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3357353b-9f8a-4f54-ad41-0fb467b738da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 3 ... 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y=np.unique(df['category'], return_inverse=True)[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ead568-aa0a-49dd-998d-97970c7b0774",
   "metadata": {},
   "source": [
    "Vamos instanciar o tokenizer do BERT que ser√° usado posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95cb2ce0-9ae9-4aa2-b75d-2726c9c63684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carloslessa@sefaz.al.gov.br/FCD/POSTECH/modulo4/02-NLP/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f70c3-af96-4882-8467-8ebcca042816",
   "metadata": {},
   "source": [
    "### Preparando o Datset\n",
    "\n",
    "Em uma primeira etapa, converteremos o conjunto de dados em tensores do pytorch, depois os empacotaremos em uma classe Dataset e, finalmente, incorporaremos o Dataset em um Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "309dc0e8-932b-44ba-8f46-c7f496b7e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_list=X.to_list()\n",
    "X_pt = tokenizer(X_list, padding='max_length', max_length = 512, truncation=True, return_tensors='pt')[\"input_ids\"]\n",
    "\n",
    "y_list=y.tolist()\n",
    "y_pt = torch.Tensor(y_list).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c6d160-4a45-483d-9127-513383d0629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pt_train, X_pt_test, y_pt_train, y_pt_test = train_test_split(X_pt, y_pt, test_size=0.3, random_state=42, stratify=y_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb5b05f-3dc9-463c-ac83-5423ffdf71cc",
   "metadata": {},
   "source": [
    "Criamos uma classe Dataset e instanciaremos os conjuntos de dados de treinamento e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f045edb6-79f0-4ea2-ab19-5526067c437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class BBCNewsDataset(Dataset):\n",
    "    \"\"\"Custom-built BBC News dataset\"\"\"\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X, y as Torch tensors\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_train[idx], self.y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d8108e-1df1-437c-bb25-0dd0700122d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obt√©m conjunto de treino e teste no formato Dataset\n",
    "train_data_pt = BBCNewsDataset(X=X_pt_train, y=y_pt_train)\n",
    "test_data_pt = BBCNewsDataset(X=X_pt_test, y=y_pt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5725a4-c278-402a-aa83-c32fc84f0535",
   "metadata": {},
   "source": [
    "Incorporamos o dataset em um Dataloader para preparar o dataset para ser usado para treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc23b65-e76c-4224-9218-2ae5dadd912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pt = DataLoader(train_data_pt, batch_size=32)\n",
    "test_loader_pt = DataLoader(test_data_pt, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ced3b2-d449-40db-8844-76f69337cc72",
   "metadata": {},
   "source": [
    "### Construindo o modelo\n",
    "\n",
    "Vamos construir o modelo. Para isso, primeiro precisamos obter a camada BERT da biblioteca do Transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b17a9c-66a9-4944-8559-53dbe3c40f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = transformers.DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "dbert_pt = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5aec4-189c-4cae-81d8-47e5cc14a74c",
   "metadata": {},
   "source": [
    "Vamos tentar entender melhor esse modelo dando uma olhada mais de perto em sua sa√≠da. Para isso, vamos pegar uma amostra do nosso conjunto de dados de treinamento (pegamos uma amostra de tamanho cinco) e olhar a sa√≠da por meio do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935ddbcc-cb54-4ecd-a9a6-1a1e0c8a5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type:  <class 'transformers.modeling_outputs.BaseModelOutput'>\n",
      "Output format (shape):  torch.Size([5, 512, 768])\n",
      "Output used as input for the classifier (shape):  torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "sample = X_pt_train[0:5]\n",
    "print('Object type: ', type(dbert_pt(sample)))\n",
    "print('Output format (shape): ',dbert_pt(sample)[0].shape)\n",
    "print('Output used as input for the classifier (shape): ', dbert_pt(sample)[0][:,0,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c2b3e-2d7b-4012-a0a8-516d729b84a3",
   "metadata": {},
   "source": [
    "A sa√≠da √© um objeto Python espec√≠fico. Entre outras informa√ß√µes, obtemos um Tensor de tamanho (N, M, S), onde N √© o tamanho do conjunto de dados (no nosso caso, cinco exemplos), M √© o comprimento da amostra (n√∫mero de palavras no texto) e S √© o tamanho do vetor de sa√≠da (a sa√≠da do modelo). Normalmente, para uma tarefa de classifica√ß√£o, usamos o primeiro vetor de sa√≠da de uma frase como entrada para o restante do modelo de classifica√ß√£o, j√° que esse primeiro vetor \"codifica\" informa√ß√µes sobre a frase geral. Alternativamente, uma m√©dia de agrupamento de todos os vetores de sa√≠da tamb√©m pode ser usada como entrada para o classificador.\n",
    "\n",
    "Agora √© hora de construir o modelo de classifica√ß√£o! Ele consistir√° em:\n",
    "\n",
    "* Modelo Distil Bert: para codificar os dados de entrada em uma nova sequ√™ncia de vetores (que √© a sa√≠da do BERT). Apenas o primeiro vetor desta sequ√™ncia ser√° usado como entrada para o resto do classificador\n",
    "* Camada de Dropout: para regulariza√ß√£o\n",
    "* Camada densa (com fun√ß√£o de ativa√ß√£o relu, com 64 neur√¥nios): para resolver o problema espec√≠fico de classifica√ß√£o\n",
    "* Camada densa (com fun√ß√£o de ativa√ß√£o softmax): para uma distribui√ß√£o de probabilidade para cada r√≥tulo\n",
    "\n",
    "A camada de Dropout √© usada apenas durante o treinamento. Alguns links entre as camadas s√£o definidos como zero de prop√≥sito, para que seus \"vizinhos\" assumam seu papel. Isso torna a previs√£o geral mais robusta. Ao usar o modelo para infer√™ncia (predi√ß√£o), as camadas de abandono s√£o ignoradas e a sa√≠da √© redimensionada de acordo. Observe que esta √© uma das raz√µes pelas quais temos que informar ao modelo se ele est√° em modo de treinamento ou avalia√ß√£o.\n",
    "\n",
    "No PyTorch, precisamos definir as camadas e, em seguida, definir uma fun√ß√£o de avan√ßo que fa√ßa uso das camadas. Cada camada obt√©m o tamanho de entrada e o tamanho de sa√≠da como par√¢metros de configura√ß√£o, ent√£o as informa√ß√µes sobre as dimens√µes dos tensores j√° est√£o contidas no pr√≥prio modelo. Por exemplo, a camada \"linear1\" obt√©m um vetor de tamanho 768 como entrada e retorna um vetor de tamanho 64 como sa√≠da. Esses dois n√∫meros s√£o parte de sua defini√ß√£o. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45c4951f-df3b-4e90-a519-39626b4d3887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class DistilBertClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistilBertClassification, self).__init__()\n",
    "        self.dbert = dbert_pt\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.linear1 = nn.Linear(768,64)\n",
    "        self.ReLu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(64,5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dbert(input_ids=x)\n",
    "        x = x[\"last_hidden_state\"][:,0,:]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.ReLu(x)\n",
    "        logits = self.linear2(x)\n",
    "        # No need for a softmax, because it is already included in the CrossEntropyLoss\n",
    "        return logits\n",
    "\n",
    "model_pt = DistilBertClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e950d3f5-65ea-4acf-a83e-a09cd4559ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertClassification(\n",
      "  (dbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
      "  (ReLu): ReLU()\n",
      "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dff1298-92f2-4afa-96e6-330c4d06900a",
   "metadata": {},
   "source": [
    "Ainda precisamos definir os par√¢metros da parte BERT do modelo como \"n√£o trein√°vel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc460cb-0141-440c-9440-c7d8438321fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_pt.dbert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fc6f79-d068-4db5-8ad9-d0736e6ce325",
   "metadata": {},
   "source": [
    "Vejamos o n√∫mero de par√¢metros (trein√°veis e n√£o trein√°veis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c1ef93-1876-4ee4-b2bf-727596725ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:  66412421\n",
      "Number of trainable parameters:  49541\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model_pt.parameters())\n",
    "total_params_trainable = sum(p.numel() for p in model_pt.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: \", total_params)\n",
    "print(\"Number of trainable parameters: \", total_params_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa8e21-3ca9-44c3-8c73-18b513581eed",
   "metadata": {},
   "source": [
    "Vamos verificar rapidamente se o n√∫mero de par√¢metros trein√°veis (que est√£o apenas nas camadas densas, BERT sendo \"congelado\") faz sentido. O vetor que sai do BERT √© um vetor de tamanho 768 (por defini√ß√£o do modelo BERT). Cada um desses elementos est√° vinculado a cada um dos 64 neur√¥nios da camada densa, levando a 768x64=49152 par√¢metros. Cada neur√¥nio tem um par√¢metro adicional, o bias, ou seja, 64 par√¢metros. A sa√≠da da camada densa consiste em 64 elementos, que se conectam a todos os cinco elementos da camada de classifica√ß√£o, ou seja, 64x5. A camada de classifica√ß√£o tamb√©m tem 5 bias.\n",
    "\n",
    "No total, o n√∫mero de par√¢metros trein√°veis √©: 768x64+64+64*5+5 = 49541! Chegamos l√° :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9b56d-1014-4573-ba61-f1c4701a3d01",
   "metadata": {},
   "source": [
    "### Treinando o Modelo\n",
    "\n",
    "Agora √© hora de treinar o modelo! Vamos fazer isso tendo em mente que queremos medir o desempenho (tanto em termos de acur√°cia quanto de tempo de treinamento), ent√£o vamos colocar a medi√ß√£o em pr√°tica.\n",
    "\n",
    "No Pytorch, precisamos definir um loop de treinamento, que far√° um loop em √©pocas (alto n√≠vel) e lotes (baixo n√≠vel). Mas, ao codificar os loops de treinamento n√≥s mesmos, isso nos d√° total transpar√™ncia sobre o que est√° sendo feito!\n",
    "\n",
    "Queremos rastrear o progresso do treinamento e, por isso, introduzimos o dicion√°rio \"history\", que coleta v√°rios indicadores-chave de desempenho durante o treinamento.\n",
    "\n",
    "Antes de come√ßarmos o treinamento, precisamos configurar o n√∫mero de √©pocas, o crit√©rio (qual √© a fun√ß√£o a ser minimizada) e o otimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d6ca0d-4322-4898-95b2-4282c7199a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_pt.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b0f9ea-acfb-4760-8698-f92fa2423f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [11:00<00:00, 13.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss:      1.130 \t\t Validation Loss:      0.578\n",
      "\t\t Training Accuracy:    66.281% \t\t Validation Accuracy:    89.521%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [10:48<00:00, 13.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 \t\t Training Loss:      0.430 \t\t Validation Loss:      0.232\n",
      "\t\t Training Accuracy:    92.421% \t\t Validation Accuracy:    94.611%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [10:51<00:00, 13.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 \t\t Training Loss:      0.238 \t\t Validation Loss:      0.156\n",
      "\t\t Training Accuracy:    95.247% \t\t Validation Accuracy:    95.359%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [10:54<00:00, 13.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 \t\t Training Loss:      0.169 \t\t Validation Loss:      0.125\n",
      "\t\t Training Accuracy:    95.825% \t\t Validation Accuracy:    95.210%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49/49 [10:52<00:00, 13.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 \t\t Training Loss:      0.142 \t\t Validation Loss:      0.111\n",
      "\t\t Training Accuracy:    96.660% \t\t Validation Accuracy:    96.257%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Define o dicion√°rio \"history\" que ir√° coletar indicadores de performance durante o treino\n",
    "history = {}\n",
    "history[\"epoch\"]=[]\n",
    "history[\"train_loss\"]=[]\n",
    "history[\"valid_loss\"]=[]\n",
    "history[\"train_accuracy\"]=[]\n",
    "history[\"valid_accuracy\"]=[]\n",
    "\n",
    "# Mensura o tempo para treinamento\n",
    "start_time = datetime.now()\n",
    "\n",
    "#¬†Loop nas √©pocas\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Configura o modo para treino\n",
    "    model_pt.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_accuracy = []\n",
    "    \n",
    "    #¬†itera sobre os batches\n",
    "    for X, y in tqdm(train_loader_pt):\n",
    "        \n",
    "        # Obt√©m predi√ß√µes e Loss\n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "        \n",
    "        # Ajusta os parametros do modelo\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        train_accuracy += accuracy\n",
    "    \n",
    "    train_accuracy = (sum(train_accuracy) / len(train_accuracy)).item()\n",
    "    \n",
    "    # Calcula a loss no conjunto de teste depois de cada √©poca\n",
    "    # Configura o modo para avaliacao\n",
    "    model_pt.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_accuracy = []\n",
    "    for X, y in test_loader_pt:\n",
    "         \n",
    "        prediction = model_pt(X)\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "        prediction_index = prediction.argmax(axis=1)\n",
    "        accuracy = (prediction_index==y)\n",
    "        valid_accuracy += accuracy\n",
    "    valid_accuracy = (sum(valid_accuracy) / len(valid_accuracy)).item()\n",
    "    \n",
    "    history[\"epoch\"].append(e+1)\n",
    "    history[\"train_loss\"].append(train_loss / len(train_loader_pt))\n",
    "    history[\"valid_loss\"].append(valid_loss / len(test_loader_pt))\n",
    "    history[\"train_accuracy\"].append(train_accuracy)\n",
    "    history[\"valid_accuracy\"].append(valid_accuracy)    \n",
    "        \n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_loader_pt) :10.3f} \\t\\t Validation Loss: {valid_loss / len(test_loader_pt) :10.3f}')\n",
    "    print(f'\\t\\t Training Accuracy: {train_accuracy :10.3%} \\t\\t Validation Accuracy: {valid_accuracy :10.3%}')\n",
    "    \n",
    "# Mensura tempo de treinamento\n",
    "end_time = datetime.now()\n",
    "training_time_pt = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81e3ba8d-e1c5-4be7-9fdd-d5c4a43cf8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb0b04b6980>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "ax[0].set(title='Loss')\n",
    "ax[0].plot(history['train_loss'], label='Training')\n",
    "ax[0].plot(history['valid_loss'], label='Validation')\n",
    "ax[0].legend(loc=\"upper right\")\n",
    "\n",
    "ax[1].set(title='Accuracy')\n",
    "ax[1].plot(history['train_accuracy'], label='Training')\n",
    "ax[1].plot(history['valid_accuracy'], label='Validation')\n",
    "ax[1].legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "027a24d0-5b7c-4e38-8335-ba8d64ec54f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training data: 96.7%\n",
      "Accuracy Test data: 96.3%\n",
      "Training time: 3493.7s (or 58.2 minutes)\n"
     ]
    }
   ],
   "source": [
    "accuracy_pt = history['valid_accuracy'][-1]\n",
    "print('Accuracy Training data: {:.1%}'.format(history['train_accuracy'][-1]))\n",
    "print('Accuracy Test data: {:.1%}'.format(history['valid_accuracy'][-1]))\n",
    "print('Training time: {:.1f}s (or {:.1f} minutes)'.format(training_time_pt, training_time_pt/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf05a3-902a-4bb7-a65d-273abda94b61",
   "metadata": {},
   "source": [
    "A acur√°cia parece boa (>95%)! Tamb√©m observamos que a acur√°cia aumenta com as √©pocas, e as acur√°cias de treino e valida√ß√£o s√£o pr√≥ximas uma da outra, o que significa que parece n√£o haver overfitting. \n",
    "\n",
    "Nosso modelo est√° treinado! Para manter este modelo, vamos salv√°-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f066ab-e44a-46ca-a785-cbdcb7f490cd",
   "metadata": {},
   "source": [
    "### Salvando o modelo\n",
    "\n",
    "Existem duas abordagens para salvar um modelo e abordaremos ambas nesta se√ß√£o.\n",
    "\n",
    "√â poss√≠vel salvar apenas os par√¢metros do modelo. Ent√£o, para carregar o modelo, primeiro teremos que instanciar o modelo (o modelo DistilBertClassification) e, em seguida, carregar todos os seus par√¢metros (treinados) neste modelo. Esta √© uma maneira conveniente de armazenar um modelo, no entanto, s√≥ √© poss√≠vel se voc√™ tiver detalhes completos sobre a arquitetura do modelo original.\n",
    "\n",
    "Uma alternativa √© salvar o modelo inteiro. Ao fazer isso, √© mais f√°cil carregar o modelo de seu local salvo. Vamos dar uma olhada nas duas abordagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3ebbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# salve apenas os parametros do modelo, mas nao o modelo em si, e recupere-o.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(model_pt\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPyModel.sd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# carregue os parametros salvos em um novo modelo\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_reloaded \u001b[38;5;241m=\u001b[39m DistilBertClassification()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Salve apenas os parametros do modelo, mas nao o modelo em si, e recupere-o.\n",
    "torch.save(model_pt.state_dict(), 'PyModel.sd')\n",
    "# carregue os parametros salvos em um novo modelo\n",
    "model_reloaded = DistilBertClassification().to(device)\n",
    "model_reloaded.load_state_dict(torch.load('PyModel.sd'))\n",
    "model_reloaded.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0573e55c-d8c9-4071-88be-a5bcad55eb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertClassification(\n",
       "  (dbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (ReLu): ReLU()\n",
       "  (linear2): Linear(in_features=64, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salve o modelo todo e recupere-o\n",
    "torch.save(model_pt, 'PyModelComplete.pt')\n",
    "model_reloaded2 = torch.load('PyModelComplete.pt', weights_only=False)\n",
    "model_reloaded2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a6224-0317-4745-b9fe-7d76c3e35c0c",
   "metadata": {},
   "source": [
    "# O que voc√™ viu nessa aula?\n",
    "\n",
    "Nessa aula, apresentamos o BERT, um LLM que pode ser usado para v√°rias tarefas em NLP. Dentre elas, apresentamos um caso para classifica√ß√£o de texto. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
